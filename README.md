# SVM-using-Numpy

Support Vector Machine is used for finding an optimal hyperplane that maximizes margin between classes. SVM’s are most commonly used for classification problem. They can also be used for regression, outlier detection and clustering. SVM works great for a small data sets.

There are two classes in the below example. One is denoted by ‘- ‘and other by ‘+’. Both the classes are plotted on a 2D graph. Using SVM, a decision boundary can be drawn that can best separates two classes. This decision boundary is called as a hyperplane. Hyperplane is a linear decision surface. For 2-dimensional space, hyperplane will be (2-1) 1 dimension. Similarly, for a three-dimensional space, hyperplane will be (3-1) 2-dimensional. 
Given two or more labelled classes of data, a discriminative classifier can be created using support vector machines. Decision boundary is drawn by maximizing the margin(space) between the line(hyperplane) and classes. Points that are closest to the decision boundary are called support. They are called so because they support the creation of the hyperplane. If these points move, the decision boundary will move as well. Maximizing the space and placing a hyperplane between classes can greatly increases the chance of new point falling into its correct class category.

Thanks to siraj for an awesome tutorial
